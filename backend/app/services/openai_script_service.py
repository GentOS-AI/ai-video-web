"""
OpenAI GPT-4o Service for Image Analysis and Script Generation
"""
import base64
import logging
from typing import Dict, Any
from io import BytesIO
from PIL import Image as PILImage
from openai import OpenAI

from app.core.config import settings

logger = logging.getLogger(__name__)


class OpenAIScriptService:
    """Service for generating scripts using OpenAI GPT-4o Vision API"""

    def __init__(self):
        if not settings.OPENAI_API_KEY:
            raise ValueError("OPENAI_API_KEY is not configured in settings")

        self.client = OpenAI(api_key=settings.OPENAI_API_KEY)
        self.model = "gpt-4o"
        logger.info(f"âœ… OpenAI Script Service initialized with model: {self.model}")

    def analyze_image_for_script(
        self,
        image_data: bytes,
        duration: int = 8,
        mime_type: str = "image/jpeg",
        language: str = "en",
        user_description: str = None  # ðŸ†• User's product description and advertising ideas
    ) -> Dict[str, Any]:
        """
        Analyze product image and generate professional advertising video script using GPT-4o

        Args:
            image_data: Image file bytes
            duration: Video duration in seconds (default: 4)
            mime_type: Image MIME type (image/jpeg or image/png)
            language: Language for script generation (en, zh, ja, etc.)

        Returns:
            Dict containing:
                - script: Complete video script description
                - style: Video style keywords
                - camera: Camera movement description
                - lighting: Lighting atmosphere
                - tokens_used: Tokens consumed

        Raises:
            Exception: If OpenAI API call fails
        """
        current_step = "initialization"
        try:
            # === Step 1: Image Validation ===
            current_step = "image_validation"
            logger.info("-" * 50)
            logger.info("ðŸ” [OpenAI Service] Step 1: Validating image")
            logger.info(f"  ðŸ“ Input size: {len(image_data) / (1024*1024):.2f}MB")
            logger.info(f"  ðŸŽ¨ MIME type: {mime_type}")
            logger.info(f"  â±ï¸  Target duration: {duration}s")
            logger.info(f"  ðŸŒ Language: {language}")

            # Load image with PIL to validate format
            img = PILImage.open(BytesIO(image_data))
            logger.info(f"  âœ… Image loaded successfully")
            logger.info(f"    Format: {img.format}")
            logger.info(f"    Size: {img.size[0]}x{img.size[1]}")
            logger.info(f"    Mode: {img.mode}")

            # === Step 2: Image Processing ===
            current_step = "image_processing"
            logger.info("-" * 50)
            logger.info("ðŸ”„ [OpenAI Service] Step 2: Processing image")

            # Convert to RGB if necessary (for PNG with alpha channel)
            if img.mode in ('RGBA', 'LA', 'P'):
                logger.info(f"  ðŸ”„ Converting {img.mode} to RGB...")
                background = PILImage.new('RGB', img.size, (255, 255, 255))
                if img.mode == 'P':
                    img = img.convert('RGBA')
                background.paste(img, mask=img.split()[-1] if img.mode == 'RGBA' else None)
                img = background
                logger.info(f"  âœ… Converted to RGB")

            # Resize if too large (max 20MB recommended for OpenAI)
            max_dimension = 2048
            original_size = img.size
            if max(img.size) > max_dimension:
                logger.info(f"  ðŸ“ Resizing image (max dimension: {max_dimension}px)...")
                ratio = max_dimension / max(img.size)
                new_size = tuple(int(dim * ratio) for dim in img.size)
                img = img.resize(new_size, PILImage.Resampling.LANCZOS)
                logger.info(f"  âœ… Resized from {original_size} to {new_size}")
            else:
                logger.info(f"  âœ… Image size OK, no resizing needed")

            # Convert to JPEG bytes
            img_byte_arr = BytesIO()
            img.save(img_byte_arr, format='JPEG', quality=95)
            processed_image_data = img_byte_arr.getvalue()
            processed_size_mb = len(processed_image_data) / (1024 * 1024)
            logger.info(f"  âœ… Processed image size: {processed_size_mb:.2f}MB")

            # === Step 3: Encode to Base64 ===
            current_step = "base64_encoding"
            logger.info("-" * 50)
            logger.info("ðŸ” [OpenAI Service] Step 3: Encoding to base64")
            base64_image = base64.b64encode(processed_image_data).decode('utf-8')
            logger.info(f"  âœ… Base64 encoded ({len(base64_image)} characters)")

            # === Step 4: Prepare Request ===
            current_step = "prepare_request"
            logger.info("-" * 50)
            logger.info("ðŸ“ [OpenAI Service] Step 4: Preparing OpenAI request")

            prompt = self._create_script_prompt(duration, language, user_description)
            logger.info(f"  âœ… Prompt created ({len(prompt)} characters)")
            logger.info(f"  ðŸ“ User input included: {'Yes' if user_description else 'No'}")

            # === Step 5: Call OpenAI API ===
            current_step = "openai_api_call"
            logger.info("-" * 50)
            logger.info("ðŸ¤– [OpenAI Service] Step 5: Calling OpenAI GPT-4o API")
            logger.info(f"  ðŸ”§ Model: {self.model}")
            logger.info(f"  ðŸŒ¡ï¸  Temperature: 0.7")
            logger.info(f"  ðŸ“Š Max tokens: 800")

            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": prompt
                            },
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{base64_image}",
                                    "detail": "high"
                                }
                            }
                        ]
                    }
                ],
                max_tokens=800,
                temperature=0.7
            )

            logger.info("  âœ… OpenAI API response received")

            # === Step 6: Process Response ===
            current_step = "process_response"
            logger.info("-" * 50)
            logger.info("ðŸ“¤ [OpenAI Service] Step 6: Processing response")

            # Extract response text
            script_text = response.choices[0].message.content
            if not script_text:
                raise Exception("OpenAI did not generate a response")

            script_text = script_text.strip()
            logger.info(f"  âœ… Script extracted ({len(script_text)} characters)")

            # Parse response
            result = self._parse_response(script_text)
            result["tokens_used"] = response.usage.total_tokens
            result["ai_provider"] = "openai-gpt-4o"

            logger.info(f"  âœ… Response parsed")
            logger.info(f"    Style: {result.get('style', 'N/A')}")
            logger.info(f"    Camera: {result.get('camera', 'N/A')}")
            logger.info(f"    Lighting: {result.get('lighting', 'N/A')}")

            logger.info("-" * 50)
            logger.info("âœ… [OpenAI Service] Script generation completed successfully")
            logger.info(f"  ðŸ“ Final script length: {len(result['script'])} characters")
            logger.info(f"  ðŸ”¢ Tokens used: {response.usage.total_tokens}")
            logger.info("-" * 50)

            return result

        except PILImage.UnidentifiedImageError as e:
            logger.error("-" * 50)
            logger.error(f"âŒ [OpenAI Service] IMAGE FORMAT ERROR at step: {current_step}")
            logger.error(f"  ðŸ’¬ Error: Cannot identify image format")
            logger.error(f"  ðŸ“ Data size: {len(image_data)} bytes")
            logger.error(f"  ðŸŽ¨ MIME type: {mime_type}")
            logger.error("-" * 50)
            raise Exception(f"Invalid image format. Please upload a valid JPG or PNG image.")

        except Exception as e:
            logger.error("-" * 50)
            logger.error(f"âŒ [OpenAI Service] ERROR at step: {current_step}")
            logger.error(f"  ðŸ”´ Error type: {type(e).__name__}")
            logger.error(f"  ðŸ’¬ Error message: {str(e)}")
            logger.error("-" * 50)
            logger.error("Full stack trace:", exc_info=True)
            raise Exception(f"Failed to generate script: {str(e)}")

    def _create_script_prompt(self, duration: int, language: str = "en", user_description: str = None) -> str:
        """Create optimized prompt for professional video script generation"""

        # Language-specific prompts
        if language == "zh":
            # æž„å»ºç”¨æˆ·è¾“å…¥éƒ¨åˆ†ï¼Œå¹¶æ ¹æ®æ˜¯å¦æœ‰ç”¨æˆ·è¾“å…¥è°ƒæ•´æŒ‡ä»¤
            if user_description:
                user_context = f"\n\n**ç”¨æˆ·æä¾›çš„äº§å“æè¿°ä¸Žå¹¿å‘Šåˆ›æ„ï¼š**\n{user_description}\n\né‡è¦æç¤ºï¼šè¯·å°†ç”¨æˆ·æè¿°ä½œä¸ºé¦–è¦å‚è€ƒã€‚ç»“åˆç”¨æˆ·æä¾›çš„ä¿¡æ¯ä¸Žå›¾åƒåˆ†æžï¼Œåˆ›ä½œæœ‰é’ˆå¯¹æ€§çš„ä¸“ä¸šå¹¿å‘Šè„šæœ¬ã€‚"
                analysis_instruction = "ä»”ç»†è§‚å¯Ÿäº§å“å›¾ç‰‡ï¼Œå¹¶ç»“åˆä¸Šè¿°ç”¨æˆ·æè¿°æ¥ï¼š"
                highlight_instruction = "- å¼ºè°ƒï¼š[åŸºäºŽç”¨æˆ·è¾“å…¥ + å›¾åƒç»†èŠ‚çš„æ ¸å¿ƒå–ç‚¹]"
            else:
                user_context = ""
                analysis_instruction = "ä»”ç»†è§‚å¯Ÿæä¾›çš„äº§å“å›¾ç‰‡ï¼Œç‹¬ç«‹åˆ†æžå¹¶è¯†åˆ«ï¼š"
                highlight_instruction = "- å¼ºè°ƒï¼š[ä»Žå›¾åƒåˆ†æžä¸­è¯†åˆ«çš„æ ¸å¿ƒå–ç‚¹]"

            return f"""ä½ æ˜¯æ‹¥æœ‰10å¹´ä»¥ä¸Šç»éªŒçš„ä¸“ä¸šå¹¿å‘Šè§†é¢‘å¯¼æ¼”ï¼Œä¸ºé¡¶çº§å“ç‰Œåˆ›ä½œè¿‡æ— æ•°æˆåŠŸçš„äº§å“å¹¿å‘Šç‰‡ã€‚

**ä»»åŠ¡ï¼š** ä¸ºè¿™ä¸ªäº§å“åˆ›ä½œä¸€ä¸ª{duration}ç§’çš„ä¸“ä¸šå¹¿å‘Šè§†é¢‘åˆ†é•œè„šæœ¬ã€‚
{user_context}

**å›¾åƒåˆ†æžï¼š** {analysis_instruction}
- äº§å“ç±»åˆ«å’Œæ ¸å¿ƒåŠŸèƒ½
- é«˜ç«¯å“è´¨å’Œç‹¬ç‰¹å–ç‚¹
- ç›®æ ‡å—ä¼—å’Œæƒ…æ„Ÿè¯‰æ±‚ç‚¹
- æœ€ä½³æ‹æ‘„è§’åº¦å’Œè§†è§‰å™äº‹æœºä¼š

**è„šæœ¬è¦æ±‚ï¼š**

ðŸ“¹ **åˆ†é•œå¤´ç»“æž„ï¼ˆå¿…é¡»éµå¾ªæ ¼å¼ï¼‰ï¼š**

ã€é•œå¤´1ã€‘(0-{duration//4}ç§’) å¼€åœº - çŽ¯å¢ƒå»ºç«‹
- çŽ¯å¢ƒï¼š[èƒŒæ™¯è®¾ç½®ï¼šå½±æ£š/ç”Ÿæ´»åœºæ™¯]
- äº§å“ï¼š[ä½ç½®ã€è§’åº¦ã€çªå‡ºç¨‹åº¦]
- è¿é•œï¼š[æŽ¨è¿›/æ‹‰è¿œ/æ‘‡ç§»/å›ºå®š]
- ç¯å…‰ï¼š[é£Žæ ¼ï¼šå½±æ£šå…‰/è‡ªç„¶å…‰/æˆå‰§å…‰ï¼Œé‡ç‚¹çªå‡º]
- æƒ…ç»ªï¼š[æƒ…æ„ŸåŸºè°ƒï¼šçŽ°ä»£/å¥¢åŽ/åŠ¨æ„Ÿ/å¹³é™]

ã€é•œå¤´2ã€‘({duration//4}-{duration//2}ç§’) ç‰¹å†™ - æ ¸å¿ƒç‰¹æ€§
- ç„¦ç‚¹ï¼š[å…·ä½“äº§å“ç»†èŠ‚ã€çº¹ç†ã€æè´¨]
{highlight_instruction}
- è¿é•œï¼š[180åº¦çŽ¯ç»•/å€¾æ–œ/è·Ÿè¸ª]
- ç¯å…‰ï¼š[å¼ºè°ƒè´¨æ„Ÿçš„é‡ç‚¹ç…§æ˜Ž]
- USPï¼š[çªå‡ºçš„ç‹¬ç‰¹åŠŸèƒ½]

ã€é•œå¤´3ã€‘({duration//2}-{duration*3//4}ç§’) åŠ¨æ€å±•ç¤º
- åŠ¨ä½œï¼š[äº§å“äº¤äº’/æ—‹è½¬/åŠŸèƒ½æ¼”ç¤º]
- ç‰¹æ•ˆï¼š[å…‰è¿¹ã€ç²’å­ã€å…‰æ™•ã€çŽ°ä»£å›¾å½¢]
- å­—å¹•ï¼š[å…³é”®åˆ©ç›Šç‚¹å…³é”®è¯]
- æƒ…æ„Ÿï¼š[æ¬²æœ›è§¦å‘ã€å‘å¾€ã€ä¿¡ä»»]

ã€é•œå¤´4ã€‘({duration*3//4}-{duration}ç§’) æ”¶å°¾ - å“ç‰Œå‘ˆçŽ°
- æž„å›¾ï¼š[äº§å“æ­£é¢ï¼Œlogoæ¸…æ™°]
- ç¯å…‰ï¼š[æ¸©æš–ã€å¸å¼•äººã€é«˜ç«¯æ„Ÿ]
- è¿é•œï¼š[ç¼“æ…¢æ‹‰è¿œï¼Œä¼˜é›…å‘ˆçŽ°]
- å“ç‰Œï¼š[Logoæ·¡å…¥ï¼Œå¦‚æœ‰æ ‡è¯­]
- CTAï¼š[è´­ä¹°æ¬²æœ›æ—¶åˆ»ï¼š"æ‹¥æœ‰å®ƒ"ã€"æŽ¢ç´¢"ã€"ä½“éªŒ"]

**å¹¿å‘ŠåŽŸåˆ™ï¼š**
âœ… å¼ºè°ƒäº§å“åˆ©ç›Šï¼Œè€Œéžä»…åŠŸèƒ½
âœ… ä¸Žç›®æ ‡å—ä¼—å»ºç«‹æƒ…æ„Ÿè¿žæŽ¥
âœ… ä½¿ç”¨é«˜ç«¯è§†è§‰è¯­è¨€ï¼ˆç”µå½±æ„Ÿã€é«˜ç«¯ï¼‰
âœ… ä¿æŒå“ç‰Œä¸€è‡´æ€§
âœ… ä»¥å¼ºçƒˆè´­ä¹°æ¬²æœ›ç»“å°¾

**æŠ€æœ¯è§„æ ¼ï¼š**
- æ€»æ—¶é•¿ï¼š{duration}ç§’
- é£Žæ ¼ï¼šç”µå½±å¹¿å‘Šç¾Žå­¦
- è°ƒè‰²ï¼šé«˜ç«¯ã€ç¬¦åˆå“ç‰Œè°ƒæ€§
- èŠ‚å¥ï¼šåŠ¨æ€ä½†ä¿¡æ¯æ¸…æ™°

**éŸ³é¢‘/å£°éŸ³è®¾è®¡è¦æ±‚ï¼š**
âš ï¸ é‡è¦ï¼šæ‰€æœ‰éŸ³é¢‘å…ƒç´ ï¼ˆèƒŒæ™¯éŸ³ä¹ã€æ—ç™½é…éŸ³ã€éŸ³æ•ˆï¼‰å¿…é¡»åœ¨è§†é¢‘ç»“æŸå‰è‡³å°‘500æ¯«ç§’ï¼ˆ0.5ç§’ï¼‰è‡ªç„¶ç»“æŸï¼Œé¿å…è¢«å¼ºåˆ¶æˆªæ–­ã€‚

- èƒŒæ™¯éŸ³ä¹ï¼šåº”ä»Žç¬¬{duration - 1}ç§’å¼€å§‹ä¼˜é›…æ·¡å‡ºï¼Œåœ¨ç¬¬{duration - 0.5}ç§’å‰å®Œå…¨é™éŸ³
- æ—ç™½é…éŸ³ï¼šæœ€åŽä¸€å¥è¯å¿…é¡»åœ¨ç¬¬{duration - 0.5}ç§’å‰è¯´å®Œï¼Œé¿å…è¢«æˆªæ–­
- éŸ³æ•ˆï¼šæœ€åŽä¸€ä¸ªéŸ³æ•ˆåº”åœ¨ç¬¬{duration - 0.5}ç§’å‰å®Œæˆ
- éŸ³é¢‘ç»“æŸé£Žæ ¼ï¼šè‡ªç„¶æ·¡å‡ºï¼Œè€Œéžçªç„¶åœæ­¢
- é™éŸ³ç¼“å†²ï¼šä¿ç•™ç¬¬{duration - 0.5}ç§’åˆ°ç¬¬{duration}ç§’ä½œä¸ºé™éŸ³ç¼“å†²ï¼ˆ500æ¯«ç§’ï¼‰

{duration}ç§’è§†é¢‘ç¤ºä¾‹ï¼š
âœ… éŸ³ä¹æ·¡å‡ºï¼šç¬¬{duration - 1}ç§’ åˆ° ç¬¬{duration - 0.5}ç§’
âœ… æœ€åŽä¸€å¥æ—ç™½ï¼šåœ¨ç¬¬{duration - 0.5}ç§’å‰ç»“æŸ
âœ… é™éŸ³ç¼“å†²ï¼šç¬¬{duration - 0.5}ç§’ åˆ° ç¬¬{duration}ç§’ï¼ˆ500æ¯«ç§’ï¼‰
âŒ ç¦æ­¢ï¼šéŸ³é¢‘æŒç»­åˆ°æœ€åŽä¸€å¸§

è¯·ç”¨ä¸­æ–‡æ’°å†™å®Œæ•´çš„åˆ†é•œå¤´å¹¿å‘Šè§†é¢‘è„šæœ¬ï¼Œä¸¥æ ¼éµå¾ªä¸Šè¿°æ ¼å¼ã€‚ç¡®ä¿æ¯ä¸ªé•œå¤´æŽ¨è¿›äº§å“æ•…äº‹ï¼Œæœå‘è´­ä¹°æ„å›¾æž„å»ºã€‚"""

        elif language == "zh-TW":
            return f"""ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„å•†æ¥­è¦–é »å°Žæ¼”,æ­£åœ¨ç‚ºé€™å€‹ç”¢å“å‰µä½œä¸€å€‹{duration}ç§’çš„å»£å‘Šè¦–é »è…³æœ¬ã€‚

è«‹ä»”ç´°è§€å¯Ÿåœ–ç‰‡ä¸­çš„ç”¢å“,ä¸¦æ’°å¯«ä¸€ä»½è©³ç´°çš„è¦–é »è£½ä½œè…³æœ¬(100-150å­—),åŒ…æ‹¬:

**è¦–è¦ºå…ƒç´ :**
- é–‹å ´é¡é ­å’Œé¡é ­é‹å‹•(æŽ¨æ‹‰æ–ç§»ã€ç‰¹å¯«)
- ç”¢å“ä½ç½®å’Œæ‹æ”è§’åº¦
- èƒŒæ™¯å’Œç’°å¢ƒä½ˆç½®
- ç‡ˆå…‰é¢¨æ ¼(å½±æ£šå…‰ã€è‡ªç„¶å…‰ã€æˆ²åŠ‡æ€§å…‰æ•ˆ)

**è£½ä½œé¢¨æ ¼:**
- è¦–è¦ºç¾Žå­¸(é›»å½±æ„Ÿã€ç¾ä»£æ„Ÿã€æ¥µç°¡ä¸»ç¾©ã€å‹•æ„Ÿ)
- èª¿è‰²å’Œæ°›åœ
- è½‰å ´å’Œç‰¹æ•ˆ
- ç¯€å¥æ„Ÿ

**è…³æœ¬æ ¼å¼:**
ä»¥é€£çºŒçš„é¡é ­æè¿°æ–¹å¼æ’°å¯«,ä¾›è¦–é »è£½ä½œåœ˜éšŠä½¿ç”¨ã€‚é‡é»žçªå‡ºç”¢å“çš„é—œéµç‰¹æ€§å’Œå¸å¼•åŠ›ã€‚

**éŸ³è¨Š/è²éŸ³è¨­è¨ˆè¦æ±‚ï¼š**
âš ï¸ é‡è¦ï¼šæ‰€æœ‰éŸ³è¨Šå…ƒç´ ï¼ˆèƒŒæ™¯éŸ³æ¨‚ã€æ—ç™½é…éŸ³ã€éŸ³æ•ˆï¼‰å¿…é ˆåœ¨è¦–é »çµæŸå‰è‡³å°‘500æ¯«ç§’ï¼ˆ0.5ç§’ï¼‰è‡ªç„¶çµæŸï¼Œé¿å…è¢«å¼·åˆ¶æˆªæ–·ã€‚

- èƒŒæ™¯éŸ³æ¨‚ï¼šæ‡‰å¾žç¬¬{duration - 1}ç§’é–‹å§‹å„ªé›…æ·¡å‡ºï¼Œåœ¨ç¬¬{duration - 0.5}ç§’å‰å®Œå…¨éœéŸ³
- æ—ç™½é…éŸ³ï¼šæœ€å¾Œä¸€å¥è©±å¿…é ˆåœ¨ç¬¬{duration - 0.5}ç§’å‰èªªå®Œï¼Œé¿å…è¢«æˆªæ–·
- éŸ³æ•ˆï¼šæœ€å¾Œä¸€å€‹éŸ³æ•ˆæ‡‰åœ¨ç¬¬{duration - 0.5}ç§’å‰å®Œæˆ
- éŸ³è¨ŠçµæŸé¢¨æ ¼ï¼šè‡ªç„¶æ·¡å‡ºï¼Œè€Œéžçªç„¶åœæ­¢
- éœéŸ³ç·©è¡ï¼šä¿ç•™ç¬¬{duration - 0.5}ç§’åˆ°ç¬¬{duration}ç§’ä½œç‚ºéœéŸ³ç·©è¡ï¼ˆ500æ¯«ç§’ï¼‰

{duration}ç§’è¦–é »ç¤ºä¾‹ï¼š
âœ… éŸ³æ¨‚æ·¡å‡ºï¼šç¬¬{duration - 1}ç§’ åˆ° ç¬¬{duration - 0.5}ç§’
âœ… æœ€å¾Œä¸€å¥æ—ç™½ï¼šåœ¨ç¬¬{duration - 0.5}ç§’å‰çµæŸ
âœ… éœéŸ³ç·©è¡ï¼šç¬¬{duration - 0.5}ç§’ åˆ° ç¬¬{duration}ç§’ï¼ˆ500æ¯«ç§’ï¼‰
âŒ ç¦æ­¢ï¼šéŸ³è¨ŠæŒçºŒåˆ°æœ€å¾Œä¸€å¹€

è«‹ç”¨ç¹é«”ä¸­æ–‡æ’°å¯«å®Œæ•´çš„è¦–é »è…³æœ¬ã€‚"""

        elif language == "ja":
            return f"""ã‚ãªãŸã¯ãƒ—ãƒ­ã®ã‚³ãƒžãƒ¼ã‚·ãƒ£ãƒ«ãƒ“ãƒ‡ã‚ªãƒ‡ã‚£ãƒ¬ã‚¯ã‚¿ãƒ¼ã§ã€ã“ã®è£½å“ã®{duration}ç§’ã®åºƒå‘Šãƒ“ãƒ‡ã‚ªã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ä½œæˆã—ã¦ã„ã¾ã™ã€‚

ç”»åƒå†…ã®è£½å“ã‚’æ³¨æ„æ·±ãè¦³å¯Ÿã—ã€è©³ç´°ãªãƒ“ãƒ‡ã‚ªåˆ¶ä½œã‚¹ã‚¯ãƒªãƒ—ãƒˆ(100-150èªž)ã‚’æ›¸ã„ã¦ãã ã•ã„:

**è¦–è¦šè¦ç´ :**
- ã‚ªãƒ¼ãƒ—ãƒ‹ãƒ³ã‚°ã‚·ãƒ§ãƒƒãƒˆã¨ã‚«ãƒ¡ãƒ©ãƒ ãƒ¼ãƒ–ãƒ¡ãƒ³ãƒˆ(ãƒ‘ãƒ³ã€ã‚ºãƒ¼ãƒ ã€ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ã€ã‚¯ãƒ­ãƒ¼ã‚ºã‚¢ãƒƒãƒ—)
- è£½å“ã®é…ç½®ã¨è§’åº¦
- èƒŒæ™¯ã¨ç’°å¢ƒè¨­å®š
- ç…§æ˜Žã‚¹ã‚¿ã‚¤ãƒ«(ã‚¹ã‚¿ã‚¸ã‚ªã€è‡ªç„¶å…‰ã€ãƒ‰ãƒ©ãƒžãƒãƒƒã‚¯)

**åˆ¶ä½œã‚¹ã‚¿ã‚¤ãƒ«:**
- ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ç¾Žå­¦(ã‚·ãƒãƒžãƒ†ã‚£ãƒƒã‚¯ã€ãƒ¢ãƒ€ãƒ³ã€ãƒŸãƒ‹ãƒžãƒªã‚¹ãƒˆã€ãƒ€ã‚¤ãƒŠãƒŸãƒƒã‚¯)
- ã‚«ãƒ©ãƒ¼ã‚°ãƒ¬ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã¨ãƒ ãƒ¼ãƒ‰
- ãƒˆãƒ©ãƒ³ã‚¸ã‚·ãƒ§ãƒ³ã¨ã‚¨ãƒ•ã‚§ã‚¯ãƒˆ
- ãƒšãƒ¼ã‚·ãƒ³ã‚°ã¨ãƒªã‚ºãƒ 

**ã‚¹ã‚¯ãƒªãƒ—ãƒˆå½¢å¼:**
ãƒ“ãƒ‡ã‚ªåˆ¶ä½œãƒãƒ¼ãƒ å‘ã‘ã®é€£ç¶šã—ãŸã‚·ãƒ§ãƒƒãƒˆãƒã‚¤ã‚·ãƒ§ãƒƒãƒˆã®èª¬æ˜Žã¨ã—ã¦æ›¸ã„ã¦ãã ã•ã„ã€‚è£½å“ã®ä¸»è¦ãªç‰¹å¾´ã¨é­…åŠ›ã‚’å¼·èª¿ã™ã‚‹è¦–è¦šçš„ãªã‚¹ãƒˆãƒ¼ãƒªãƒ¼ãƒ†ãƒªãƒ³ã‚°ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ãã ã•ã„ã€‚

**ã‚ªãƒ¼ãƒ‡ã‚£ã‚ª/ã‚µã‚¦ãƒ³ãƒ‰ãƒ‡ã‚¶ã‚¤ãƒ³è¦ä»¶ï¼š**
âš ï¸ é‡è¦ï¼šã™ã¹ã¦ã®ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªè¦ç´ ï¼ˆãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ãƒŸãƒ¥ãƒ¼ã‚¸ãƒƒã‚¯ã€ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã€åŠ¹æžœéŸ³ï¼‰ã¯ã€ãƒ“ãƒ‡ã‚ªçµ‚äº†ã®å°‘ãªãã¨ã‚‚500ãƒŸãƒªç§’ï¼ˆ0.5ç§’ï¼‰å‰ã«è‡ªç„¶ã«çµ‚äº†ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚å¼·åˆ¶çš„ãªã‚«ãƒƒãƒˆã‚ªãƒ•ã‚’é¿ã‘ã‚‹ãŸã‚ã€‚

- ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ãƒŸãƒ¥ãƒ¼ã‚¸ãƒƒã‚¯ï¼š{duration - 1}ç§’ã‹ã‚‰ã‚¨ãƒ¬ã‚¬ãƒ³ãƒˆã«ãƒ•ã‚§ãƒ¼ãƒ‰ã‚¢ã‚¦ãƒˆã—ã€{duration - 0.5}ç§’å‰ã«å®Œå…¨ã«ç„¡éŸ³ã«ã™ã‚‹
- ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼šæœ€å¾Œã®è¨€è‘‰ã¯{duration - 0.5}ç§’å‰ã«çµ‚ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™
- åŠ¹æžœéŸ³ï¼šæœ€å¾Œã®åŠ¹æžœéŸ³ã¯{duration - 0.5}ç§’å‰ã«å®Œäº†ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™
- ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªçµ‚äº†ã‚¹ã‚¿ã‚¤ãƒ«ï¼šè‡ªç„¶ãªãƒ•ã‚§ãƒ¼ãƒ‰ã‚¢ã‚¦ãƒˆã€çªç„¶ã®åœæ­¢ã§ã¯ãªã„
- ç„¡éŸ³ãƒãƒƒãƒ•ã‚¡ï¼š{duration - 0.5}ç§’ã‹ã‚‰{duration}ç§’ã‚’ç„¡éŸ³ãƒãƒƒãƒ•ã‚¡ã¨ã—ã¦ä¿æŒï¼ˆ500ãƒŸãƒªç§’ï¼‰

{duration}ç§’ã®ãƒ“ãƒ‡ã‚ªã®ä¾‹ï¼š
âœ… éŸ³æ¥½ãƒ•ã‚§ãƒ¼ãƒ‰ã‚¢ã‚¦ãƒˆï¼š{duration - 1}ç§’ ã‹ã‚‰ {duration - 0.5}ç§’
âœ… æœ€å¾Œã®ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼š{duration - 0.5}ç§’å‰ã«çµ‚äº†
âœ… ç„¡éŸ³ãƒãƒƒãƒ•ã‚¡ï¼š{duration - 0.5}ç§’ ã‹ã‚‰ {duration}ç§’ï¼ˆ500ãƒŸãƒªç§’ï¼‰
âŒ ç¦æ­¢ï¼šæœ€å¾Œã®ãƒ•ãƒ¬ãƒ¼ãƒ ã¾ã§ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚’ç¶šã‘ã‚‹

æ—¥æœ¬èªžã§å®Œå…¨ãªãƒ“ãƒ‡ã‚ªã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’æ›¸ã„ã¦ãã ã•ã„ã€‚"""

        else:  # English (default)
            # Build user context section and adjust instructions based on whether user input exists
            if user_description:
                user_context = f"\n\n**User's Product Description & Advertising Ideas:**\n{user_description}\n\nIMPORTANT: Use this as your PRIMARY reference. Combine the user's insights with what you see in the image to create a targeted, effective advertising script."
                analysis_instruction = "Carefully observe the product image and COMBINE it with the user's description above to:"
                highlight_instruction = "- Highlight: [Core selling point based on USER INPUT + image details]"
            else:
                user_context = ""
                analysis_instruction = "Carefully observe the product image provided and INDEPENDENTLY identify:"
                highlight_instruction = "- Highlight: [Core selling point identified from image analysis]"

            return f"""You are a professional advertising video director with 10+ years of experience creating compelling product commercials for top brands.

**Task:** Create a detailed {duration}-second advertising video script with shot-by-shot breakdown.
{user_context}

**Image Analysis:** {analysis_instruction}
- Product category and key features
- Premium qualities and unique selling points
- Target audience and emotional appeal
- Best angles and visual storytelling opportunities

**Script Requirements:**

ðŸ“¹ **SHOT-BY-SHOT STRUCTURE (Mandatory Format):**

ã€Shot 1ã€‘(0-{duration//4}s) Opening - Establishing Shot
- Environment: [Background setting, studio/lifestyle]
- Product: [Positioning, angle, prominence]
- Camera: [Movement: push in/pull out/pan/static]
- Lighting: [Style: studio/natural/dramatic, key highlights]
- Mood: [Emotional tone: modern/luxury/energetic/calm]

ã€Shot 2ã€‘({duration//4}-{duration//2}s) Close-up - Key Features
- Focus: [Specific product details, textures, materials]
{highlight_instruction}
- Camera: [Movement: 180Â° rotation/tilt/tracking]
- Lighting: [Accent lighting to emphasize quality]
- USP: [Unique feature that stands out]

ã€Shot 3ã€‘({duration//2}-{duration*3//4}s) Dynamic Demonstration
- Action: [Product interaction/rotation/functional demo]
- Effects: [Light trails, particles, glow, modern graphics]
- Text Overlay: [Key benefit keyword]
- Emotion: [Desire trigger, aspiration, trust]

ã€Shot 4ã€‘({duration*3//4}-{duration}s) Closing - Brand Presence
- Composition: [Product front-facing, logo visible]
- Lighting: [Warm, inviting, premium feel]
- Camera: [Slow pullback, elegant reveal]
- Branding: [Logo fade-in, tagline if applicable]
- CTA: [Call-to-action emotion: "Own it", "Discover", "Experience"]

**Advertising Principles:**
âœ… Emphasize product benefits, not just features
âœ… Create emotional connection with target audience
âœ… Use premium visual language (cinematic, high-end)
âœ… Maintain brand consistency throughout
âœ… End with strong desire-to-purchase moment

**Technical Specs:**
- Total duration: {duration} seconds
- Style: Cinematic advertising aesthetic
- Color grading: Premium, brand-appropriate
- Pacing: Dynamic but clear messaging

**Audio/Sound Design Requirements:**
âš ï¸ CRITICAL: All audio elements (background music, voiceover, sound effects) MUST naturally conclude at least 500ms (0.5 seconds) BEFORE the video ends to avoid abrupt cutoff.

- Background Music: Should fade out gracefully starting from {duration - 1}s, completely silent by {duration - 0.5}s
- Voiceover/Narration: Final words must finish by {duration - 0.5}s to avoid being cut off
- Sound Effects: Last sound effect should complete by {duration - 0.5}s
- Audio Ending Style: Natural fade-out, NOT abrupt stop
- Silent Buffer: Keep {duration - 0.5}s to {duration}s as silent buffer (500ms)

Example for {duration}s video:
âœ… Music fades out: {duration - 1}s to {duration - 0.5}s
âœ… Last narration word: ends by {duration - 0.5}s
âœ… Silent buffer: {duration - 0.5}s to {duration}s (500ms)
âŒ DO NOT: Continue audio until the last frame

Write the complete shot-by-shot advertising video script in English, following the exact format above. Ensure each shot advances the product story and builds towards purchase intent."""

    def _parse_response(self, response_text: str) -> Dict[str, Any]:
        """
        Parse OpenAI response into structured format

        Args:
            response_text: Raw text from OpenAI

        Returns:
            Structured dictionary with script components
        """
        # Try to extract JSON if present
        import json
        import re

        json_match = re.search(r'\{[^{}]*\}', response_text, re.DOTALL)
        if json_match:
            try:
                parsed = json.loads(json_match.group())
                if "script" in parsed:
                    return parsed
            except json.JSONDecodeError:
                pass

        # If no JSON found, return as complete script
        # Try to extract style, camera, lighting keywords
        result = {"script": response_text}

        # Extract style keywords
        style_keywords = ["cinematic", "vibrant", "minimalist", "modern", "dramatic", "elegant", "dynamic"]
        found_styles = [kw for kw in style_keywords if kw.lower() in response_text.lower()]
        if found_styles:
            result["style"] = ", ".join(found_styles)

        # Extract camera movements
        camera_keywords = ["zoom", "pan", "tracking", "close-up", "wide shot", "dolly", "crane"]
        found_camera = [kw for kw in camera_keywords if kw.lower() in response_text.lower()]
        if found_camera:
            result["camera"] = ", ".join(found_camera)

        # Extract lighting
        lighting_keywords = ["studio lighting", "natural light", "dramatic", "soft light", "hard light"]
        found_lighting = [kw for kw in lighting_keywords if kw.lower() in response_text.lower()]
        if found_lighting:
            result["lighting"] = ", ".join(found_lighting)

        return result


# Singleton instance
openai_script_service = OpenAIScriptService()
