"""
OpenAI GPT-4o Service for Image Analysis and Script Generation
"""
import base64
import logging
from typing import Dict, Any
from io import BytesIO
from PIL import Image as PILImage
from openai import OpenAI

from app.core.config import settings

logger = logging.getLogger(__name__)


class OpenAIScriptService:
    """Service for generating scripts using OpenAI GPT-4o Vision API"""

    def __init__(self):
        if not settings.OPENAI_API_KEY:
            raise ValueError("OPENAI_API_KEY is not configured in settings")

        self.client = OpenAI(api_key=settings.OPENAI_API_KEY)
        self.model = "gpt-4o"
        logger.info(f"âœ… OpenAI Script Service initialized with model: {self.model}")

    def analyze_image_for_script(
        self,
        image_data: bytes,
        duration: int = 4,
        mime_type: str = "image/jpeg",
        language: str = "en"
    ) -> Dict[str, Any]:
        """
        Analyze product image and generate professional advertising video script using GPT-4o

        Args:
            image_data: Image file bytes
            duration: Video duration in seconds (default: 4)
            mime_type: Image MIME type (image/jpeg or image/png)
            language: Language for script generation (en, zh, ja, etc.)

        Returns:
            Dict containing:
                - script: Complete video script description
                - style: Video style keywords
                - camera: Camera movement description
                - lighting: Lighting atmosphere
                - tokens_used: Tokens consumed

        Raises:
            Exception: If OpenAI API call fails
        """
        current_step = "initialization"
        try:
            # === Step 1: Image Validation ===
            current_step = "image_validation"
            logger.info("-" * 50)
            logger.info("ðŸ” [OpenAI Service] Step 1: Validating image")
            logger.info(f"  ðŸ“ Input size: {len(image_data) / (1024*1024):.2f}MB")
            logger.info(f"  ðŸŽ¨ MIME type: {mime_type}")
            logger.info(f"  â±ï¸  Target duration: {duration}s")
            logger.info(f"  ðŸŒ Language: {language}")

            # Load image with PIL to validate format
            img = PILImage.open(BytesIO(image_data))
            logger.info(f"  âœ… Image loaded successfully")
            logger.info(f"    Format: {img.format}")
            logger.info(f"    Size: {img.size[0]}x{img.size[1]}")
            logger.info(f"    Mode: {img.mode}")

            # === Step 2: Image Processing ===
            current_step = "image_processing"
            logger.info("-" * 50)
            logger.info("ðŸ”„ [OpenAI Service] Step 2: Processing image")

            # Convert to RGB if necessary (for PNG with alpha channel)
            if img.mode in ('RGBA', 'LA', 'P'):
                logger.info(f"  ðŸ”„ Converting {img.mode} to RGB...")
                background = PILImage.new('RGB', img.size, (255, 255, 255))
                if img.mode == 'P':
                    img = img.convert('RGBA')
                background.paste(img, mask=img.split()[-1] if img.mode == 'RGBA' else None)
                img = background
                logger.info(f"  âœ… Converted to RGB")

            # Resize if too large (max 20MB recommended for OpenAI)
            max_dimension = 2048
            original_size = img.size
            if max(img.size) > max_dimension:
                logger.info(f"  ðŸ“ Resizing image (max dimension: {max_dimension}px)...")
                ratio = max_dimension / max(img.size)
                new_size = tuple(int(dim * ratio) for dim in img.size)
                img = img.resize(new_size, PILImage.Resampling.LANCZOS)
                logger.info(f"  âœ… Resized from {original_size} to {new_size}")
            else:
                logger.info(f"  âœ… Image size OK, no resizing needed")

            # Convert to JPEG bytes
            img_byte_arr = BytesIO()
            img.save(img_byte_arr, format='JPEG', quality=95)
            processed_image_data = img_byte_arr.getvalue()
            processed_size_mb = len(processed_image_data) / (1024 * 1024)
            logger.info(f"  âœ… Processed image size: {processed_size_mb:.2f}MB")

            # === Step 3: Encode to Base64 ===
            current_step = "base64_encoding"
            logger.info("-" * 50)
            logger.info("ðŸ” [OpenAI Service] Step 3: Encoding to base64")
            base64_image = base64.b64encode(processed_image_data).decode('utf-8')
            logger.info(f"  âœ… Base64 encoded ({len(base64_image)} characters)")

            # === Step 4: Prepare Request ===
            current_step = "prepare_request"
            logger.info("-" * 50)
            logger.info("ðŸ“ [OpenAI Service] Step 4: Preparing OpenAI request")

            prompt = self._create_script_prompt(duration, language)
            logger.info(f"  âœ… Prompt created ({len(prompt)} characters)")

            # === Step 5: Call OpenAI API ===
            current_step = "openai_api_call"
            logger.info("-" * 50)
            logger.info("ðŸ¤– [OpenAI Service] Step 5: Calling OpenAI GPT-4o API")
            logger.info(f"  ðŸ”§ Model: {self.model}")
            logger.info(f"  ðŸŒ¡ï¸  Temperature: 0.7")
            logger.info(f"  ðŸ“Š Max tokens: 800")

            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": prompt
                            },
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{base64_image}",
                                    "detail": "high"
                                }
                            }
                        ]
                    }
                ],
                max_tokens=800,
                temperature=0.7
            )

            logger.info("  âœ… OpenAI API response received")

            # === Step 6: Process Response ===
            current_step = "process_response"
            logger.info("-" * 50)
            logger.info("ðŸ“¤ [OpenAI Service] Step 6: Processing response")

            # Extract response text
            script_text = response.choices[0].message.content
            if not script_text:
                raise Exception("OpenAI did not generate a response")

            script_text = script_text.strip()
            logger.info(f"  âœ… Script extracted ({len(script_text)} characters)")

            # Parse response
            result = self._parse_response(script_text)
            result["tokens_used"] = response.usage.total_tokens
            result["ai_provider"] = "openai-gpt-4o"

            logger.info(f"  âœ… Response parsed")
            logger.info(f"    Style: {result.get('style', 'N/A')}")
            logger.info(f"    Camera: {result.get('camera', 'N/A')}")
            logger.info(f"    Lighting: {result.get('lighting', 'N/A')}")

            logger.info("-" * 50)
            logger.info("âœ… [OpenAI Service] Script generation completed successfully")
            logger.info(f"  ðŸ“ Final script length: {len(result['script'])} characters")
            logger.info(f"  ðŸ”¢ Tokens used: {response.usage.total_tokens}")
            logger.info("-" * 50)

            return result

        except PILImage.UnidentifiedImageError as e:
            logger.error("-" * 50)
            logger.error(f"âŒ [OpenAI Service] IMAGE FORMAT ERROR at step: {current_step}")
            logger.error(f"  ðŸ’¬ Error: Cannot identify image format")
            logger.error(f"  ðŸ“ Data size: {len(image_data)} bytes")
            logger.error(f"  ðŸŽ¨ MIME type: {mime_type}")
            logger.error("-" * 50)
            raise Exception(f"Invalid image format. Please upload a valid JPG or PNG image.")

        except Exception as e:
            logger.error("-" * 50)
            logger.error(f"âŒ [OpenAI Service] ERROR at step: {current_step}")
            logger.error(f"  ðŸ”´ Error type: {type(e).__name__}")
            logger.error(f"  ðŸ’¬ Error message: {str(e)}")
            logger.error("-" * 50)
            logger.error("Full stack trace:", exc_info=True)
            raise Exception(f"Failed to generate script: {str(e)}")

    def _create_script_prompt(self, duration: int, language: str = "en") -> str:
        """Create optimized prompt for professional video script generation"""

        # Language-specific prompts
        if language == "zh":
            return f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å•†ä¸šè§†é¢‘å¯¼æ¼”,æ­£åœ¨ä¸ºè¿™ä¸ªäº§å“åˆ›ä½œä¸€ä¸ª{duration}ç§’çš„å¹¿å‘Šè§†é¢‘è„šæœ¬ã€‚

è¯·ä»”ç»†è§‚å¯Ÿå›¾ç‰‡ä¸­çš„äº§å“,å¹¶æ’°å†™ä¸€ä»½è¯¦ç»†çš„è§†é¢‘åˆ¶ä½œè„šæœ¬(100-150å­—),åŒ…æ‹¬:

**è§†è§‰å…ƒç´ :**
- å¼€åœºé•œå¤´å’Œé•œå¤´è¿åŠ¨(æŽ¨æ‹‰æ‘‡ç§»ã€ç‰¹å†™)
- äº§å“ä½ç½®å’Œæ‹æ‘„è§’åº¦
- èƒŒæ™¯å’ŒçŽ¯å¢ƒå¸ƒç½®
- ç¯å…‰é£Žæ ¼(å½±æ£šå…‰ã€è‡ªç„¶å…‰ã€æˆå‰§æ€§å…‰æ•ˆ)

**åˆ¶ä½œé£Žæ ¼:**
- è§†è§‰ç¾Žå­¦(ç”µå½±æ„Ÿã€çŽ°ä»£æ„Ÿã€æžç®€ä¸»ä¹‰ã€åŠ¨æ„Ÿ)
- è°ƒè‰²å’Œæ°›å›´
- è½¬åœºå’Œç‰¹æ•ˆ
- èŠ‚å¥æ„Ÿ

**è„šæœ¬æ ¼å¼:**
ä»¥è¿žç»­çš„é•œå¤´æè¿°æ–¹å¼æ’°å†™,ä¾›è§†é¢‘åˆ¶ä½œå›¢é˜Ÿä½¿ç”¨ã€‚é‡ç‚¹çªå‡ºäº§å“çš„å…³é”®ç‰¹æ€§å’Œå¸å¼•åŠ›ã€‚

è¯·ç”¨ä¸­æ–‡æ’°å†™å®Œæ•´çš„è§†é¢‘è„šæœ¬ã€‚"""

        elif language == "zh-TW":
            return f"""ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„å•†æ¥­è¦–é »å°Žæ¼”,æ­£åœ¨ç‚ºé€™å€‹ç”¢å“å‰µä½œä¸€å€‹{duration}ç§’çš„å»£å‘Šè¦–é »è…³æœ¬ã€‚

è«‹ä»”ç´°è§€å¯Ÿåœ–ç‰‡ä¸­çš„ç”¢å“,ä¸¦æ’°å¯«ä¸€ä»½è©³ç´°çš„è¦–é »è£½ä½œè…³æœ¬(100-150å­—),åŒ…æ‹¬:

**è¦–è¦ºå…ƒç´ :**
- é–‹å ´é¡é ­å’Œé¡é ­é‹å‹•(æŽ¨æ‹‰æ–ç§»ã€ç‰¹å¯«)
- ç”¢å“ä½ç½®å’Œæ‹æ”è§’åº¦
- èƒŒæ™¯å’Œç’°å¢ƒä½ˆç½®
- ç‡ˆå…‰é¢¨æ ¼(å½±æ£šå…‰ã€è‡ªç„¶å…‰ã€æˆ²åŠ‡æ€§å…‰æ•ˆ)

**è£½ä½œé¢¨æ ¼:**
- è¦–è¦ºç¾Žå­¸(é›»å½±æ„Ÿã€ç¾ä»£æ„Ÿã€æ¥µç°¡ä¸»ç¾©ã€å‹•æ„Ÿ)
- èª¿è‰²å’Œæ°›åœ
- è½‰å ´å’Œç‰¹æ•ˆ
- ç¯€å¥æ„Ÿ

**è…³æœ¬æ ¼å¼:**
ä»¥é€£çºŒçš„é¡é ­æè¿°æ–¹å¼æ’°å¯«,ä¾›è¦–é »è£½ä½œåœ˜éšŠä½¿ç”¨ã€‚é‡é»žçªå‡ºç”¢å“çš„é—œéµç‰¹æ€§å’Œå¸å¼•åŠ›ã€‚

è«‹ç”¨ç¹é«”ä¸­æ–‡æ’°å¯«å®Œæ•´çš„è¦–é »è…³æœ¬ã€‚"""

        elif language == "ja":
            return f"""ã‚ãªãŸã¯ãƒ—ãƒ­ã®ã‚³ãƒžãƒ¼ã‚·ãƒ£ãƒ«ãƒ“ãƒ‡ã‚ªãƒ‡ã‚£ãƒ¬ã‚¯ã‚¿ãƒ¼ã§ã€ã“ã®è£½å“ã®{duration}ç§’ã®åºƒå‘Šãƒ“ãƒ‡ã‚ªã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ä½œæˆã—ã¦ã„ã¾ã™ã€‚

ç”»åƒå†…ã®è£½å“ã‚’æ³¨æ„æ·±ãè¦³å¯Ÿã—ã€è©³ç´°ãªãƒ“ãƒ‡ã‚ªåˆ¶ä½œã‚¹ã‚¯ãƒªãƒ—ãƒˆ(100-150èªž)ã‚’æ›¸ã„ã¦ãã ã•ã„:

**è¦–è¦šè¦ç´ :**
- ã‚ªãƒ¼ãƒ—ãƒ‹ãƒ³ã‚°ã‚·ãƒ§ãƒƒãƒˆã¨ã‚«ãƒ¡ãƒ©ãƒ ãƒ¼ãƒ–ãƒ¡ãƒ³ãƒˆ(ãƒ‘ãƒ³ã€ã‚ºãƒ¼ãƒ ã€ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ã€ã‚¯ãƒ­ãƒ¼ã‚ºã‚¢ãƒƒãƒ—)
- è£½å“ã®é…ç½®ã¨è§’åº¦
- èƒŒæ™¯ã¨ç’°å¢ƒè¨­å®š
- ç…§æ˜Žã‚¹ã‚¿ã‚¤ãƒ«(ã‚¹ã‚¿ã‚¸ã‚ªã€è‡ªç„¶å…‰ã€ãƒ‰ãƒ©ãƒžãƒãƒƒã‚¯)

**åˆ¶ä½œã‚¹ã‚¿ã‚¤ãƒ«:**
- ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ç¾Žå­¦(ã‚·ãƒãƒžãƒ†ã‚£ãƒƒã‚¯ã€ãƒ¢ãƒ€ãƒ³ã€ãƒŸãƒ‹ãƒžãƒªã‚¹ãƒˆã€ãƒ€ã‚¤ãƒŠãƒŸãƒƒã‚¯)
- ã‚«ãƒ©ãƒ¼ã‚°ãƒ¬ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã¨ãƒ ãƒ¼ãƒ‰
- ãƒˆãƒ©ãƒ³ã‚¸ã‚·ãƒ§ãƒ³ã¨ã‚¨ãƒ•ã‚§ã‚¯ãƒˆ
- ãƒšãƒ¼ã‚·ãƒ³ã‚°ã¨ãƒªã‚ºãƒ 

**ã‚¹ã‚¯ãƒªãƒ—ãƒˆå½¢å¼:**
ãƒ“ãƒ‡ã‚ªåˆ¶ä½œãƒãƒ¼ãƒ å‘ã‘ã®é€£ç¶šã—ãŸã‚·ãƒ§ãƒƒãƒˆãƒã‚¤ã‚·ãƒ§ãƒƒãƒˆã®èª¬æ˜Žã¨ã—ã¦æ›¸ã„ã¦ãã ã•ã„ã€‚è£½å“ã®ä¸»è¦ãªç‰¹å¾´ã¨é­…åŠ›ã‚’å¼·èª¿ã™ã‚‹è¦–è¦šçš„ãªã‚¹ãƒˆãƒ¼ãƒªãƒ¼ãƒ†ãƒªãƒ³ã‚°ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ãã ã•ã„ã€‚

æ—¥æœ¬èªžã§å®Œå…¨ãªãƒ“ãƒ‡ã‚ªã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’æ›¸ã„ã¦ãã ã•ã„ã€‚"""

        else:  # English (default)
            return f"""You are a professional commercial video director. Look at the product image provided and create a detailed {duration}-second advertising video production script.

Based on what you see in the image, write a shot-by-shot script (100-150 words) that includes:

**Visual Elements:**
- Opening shot and camera movements (pan, zoom, tracking, close-up)
- Product positioning and angles
- Background and environment setup
- Lighting style (studio, natural, dramatic)

**Production Style:**
- Visual aesthetic (cinematic, modern, minimalist, dynamic)
- Color grading and mood
- Transitions and effects
- Pacing and rhythm

**Script Format:**
Write as a continuous shot-by-shot description for a video production team. Focus on visual storytelling that highlights the product's key features and appeal based on what you observe in the image.

Example format:
"Opening with a dramatic wide shot, camera slowly zooms into the [product] against a minimalist white backdrop. Soft studio lighting creates subtle shadows, emphasizing the product's sleek design. Camera executes a smooth 360Â° rotation, showcasing premium materials and craftsmanship. Close-up reveals intricate details as vibrant colors pop against the clean background. Final shot pulls back with a subtle glow effect, logo fades in. Modern, cinematic aesthetic throughout."

Write the complete video script in English based on the product image."""

    def _parse_response(self, response_text: str) -> Dict[str, Any]:
        """
        Parse OpenAI response into structured format

        Args:
            response_text: Raw text from OpenAI

        Returns:
            Structured dictionary with script components
        """
        # Try to extract JSON if present
        import json
        import re

        json_match = re.search(r'\{[^{}]*\}', response_text, re.DOTALL)
        if json_match:
            try:
                parsed = json.loads(json_match.group())
                if "script" in parsed:
                    return parsed
            except json.JSONDecodeError:
                pass

        # If no JSON found, return as complete script
        # Try to extract style, camera, lighting keywords
        result = {"script": response_text}

        # Extract style keywords
        style_keywords = ["cinematic", "vibrant", "minimalist", "modern", "dramatic", "elegant", "dynamic"]
        found_styles = [kw for kw in style_keywords if kw.lower() in response_text.lower()]
        if found_styles:
            result["style"] = ", ".join(found_styles)

        # Extract camera movements
        camera_keywords = ["zoom", "pan", "tracking", "close-up", "wide shot", "dolly", "crane"]
        found_camera = [kw for kw in camera_keywords if kw.lower() in response_text.lower()]
        if found_camera:
            result["camera"] = ", ".join(found_camera)

        # Extract lighting
        lighting_keywords = ["studio lighting", "natural light", "dramatic", "soft light", "hard light"]
        found_lighting = [kw for kw in lighting_keywords if kw.lower() in response_text.lower()]
        if found_lighting:
            result["lighting"] = ", ".join(found_lighting)

        return result


# Singleton instance
openai_script_service = OpenAIScriptService()
